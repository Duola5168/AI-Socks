# AI æ™ºæ…§æŠ•è³‡å¹³å°

ä¸€å€‹å…¨åŠŸèƒ½çš„ AI æ™ºæ…§æŠ•è³‡è¼”åŠ©å¹³å°ã€‚æ•´åˆäº†å³æ™‚ï¼ˆæ¨¡æ“¬ï¼‰æ•¸æ“šã€å‹•æ…‹è‚¡ç¥¨ç¯©é¸ã€æŠ•è³‡çµ„åˆç®¡ç†ã€äº¤æ˜“æ­·å²è¿½è¹¤å’Œé€²éš AI åˆ†æåŠŸèƒ½ã€‚æ‰€æœ‰è³‡æ–™çš†å®‰å…¨åœ°å„²å­˜åœ¨æ‚¨çš„ç€è¦½å™¨æœ¬æ©Ÿå„²å­˜ç©ºé–“ä¸­ï¼Œä¸¦å¯é¸æ“‡é€é Firebase ç™»å…¥ä»¥é€²è¡Œé›²ç«¯åŒæ­¥ã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

- **AI æ™ºæ…§é¸è‚¡:** æä¾›å¤šç¨®å…§å»ºç­–ç•¥ï¼ˆå¦‚æ³¢æ®µçªç ´ã€é•·æœŸæŠ•è³‡ã€åƒ¹å€¼ä½ä¼°ç­‰ï¼‰ï¼Œåˆ©ç”¨ Gemini AI å¾æ•¸åƒæª”è‚¡ç¥¨ä¸­å¿«é€Ÿç¯©é¸å‡ºæ½›åŠ›æ¨™çš„ã€‚
- **AI å°ˆå®¶å°çµ„è©•æ¯”:** å•Ÿç”¨ä¸€å€‹ç”±å¤šå€‹å¤§å‹èªè¨€æ¨¡å‹çµ„æˆçš„ã€ŒAI å°ˆå®¶è¾¯è«–åœ˜éšŠã€ï¼Œå°å–®ä¸€è‚¡ç¥¨é€²è¡Œæ·±åº¦ã€å¤šè§’åº¦çš„åˆ†æã€‚åœ˜éšŠæˆå“¡åŒ…å«ï¼š
    - **æ­£æ–¹åˆ†æå¸« (Gemini):** æ‰®æ¼”æ¨‚è§€æ´¾ï¼Œå°ˆæ³¨æŒ–æ˜æ½›åœ¨åˆ©å¤šèˆ‡æˆé•·æ©Ÿæœƒã€‚
    - **åæ–¹åˆ†æå¸« (Groq):** æ‰®æ¼”ä¿å®ˆæ´¾ï¼Œå°ˆæ³¨è©•ä¼°æ½›åœ¨é¢¨éšªèˆ‡ç‡Ÿé‹ç–‘æ…®ã€‚
    - **ç¬¬ä¸‰æ–¹ä¸­ç«‹åˆ†æå¸« (GitHub Models):** æä¾›å®¢è§€çš„æ•¸æ“šç¶œåˆåˆ†æèˆ‡æƒ…å¢ƒæ¨¡æ“¬ã€‚
    - **æŠ•è³‡ç¸½ç›£ (CIO - Gemini):** æ•´åˆæ‰€æœ‰è¡çªèˆ‡å…±è­˜è§€é»ï¼Œåšå‡ºæœ€çµ‚çš„ã€åŒ…å«è³‡é‡‘é…ç½®èˆ‡é¢¨æ§ç­–ç•¥çš„æ¬Šå¨å†³ç­–ã€‚
- **å³æ™‚æŠ•è³‡çµ„åˆè¿½è¹¤:** è‡ªå‹•æ›´æ–°æŒè‚¡çš„å³æ™‚åƒ¹æ ¼èˆ‡æç›Šï¼Œä¸¦æ ¹æ“šæ‚¨çš„ç­–ç•¥è¨­å®šæä¾›å‹•æ…‹çš„åœæã€åœåˆ©æˆ–è¤‡ç›¤è­¦ç¤ºã€‚
- **äº¤æ˜“æ­·å²èˆ‡ AI è¤‡ç›¤:** è¨˜éŒ„æ¯ä¸€ç­†å·²å¯¦ç¾çš„äº¤æ˜“ï¼Œä¸¦åˆ©ç”¨ AI é€²è¡Œç­–ç•¥è©•ä¼°èˆ‡å„ªåŒ–å»ºè­°ï¼Œå¹«åŠ©æ‚¨å¾éå»çš„ç¶“é©—ä¸­å­¸ç¿’ã€‚
- **AI åˆ†æå¸«è¨­å®š:** è‡ªç”±å•Ÿç”¨æˆ–åœç”¨ä¸åŒçš„ AI æ¨¡å‹ï¼Œä»¥ç®¡ç† API æˆæœ¬èˆ‡ç”¨é‡ã€‚
- **ç³»çµ±ç›£æ§å„€è¡¨æ¿:** ä¸€ç«™å¼æª¢æŸ¥æ‰€æœ‰å¤–éƒ¨ API æœå‹™ï¼ˆè­‰äº¤æ‰€ã€FinMindã€AI æ¨¡å‹ï¼‰çš„é€£ç·šç‹€æ…‹ï¼Œä¸¦ç®¡ç†æœ¬åœ°èˆ‡é›²ç«¯è³‡æ–™åº«çš„åŒæ­¥ã€‚

## ğŸš€ æŠ€è¡“æ£§

- **å‰ç«¯:** React, Vite, TypeScript, Tailwind CSS
- **AI / å¤§å‹èªè¨€æ¨¡å‹:** Google Gemini, Groq (Llama 3), GitHub Models (OpenAI, DeepSeek, xAI)
- **æ•¸æ“šæœå‹™:** 
    - Firebase (èªè­‰èˆ‡é›²ç«¯è³‡æ–™åº«)
    - Netlify Functions (ä½œç‚ºå¾Œç«¯ä»£ç†)
    - **Supabase (æ ¸å¿ƒå¸‚å ´æ•¸æ“šåº«)**
- **å¾Œç«¯æ•¸æ“šæ›´æ–°:** **æœ¬åœ° Python è…³æœ¬**
- **è³‡æ–™ä¾†æº:** FinMind API, è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€ OpenAPI, NewsAPI, yfinance, twstock

## éƒ¨ç½²æŒ‡å— (Deployment Guide)

### å‰ç«¯éƒ¨ç½² (Netlify)

1.  **ä¸Šå‚³è‡³ GitHub:** å°‡æ•´å€‹å°ˆæ¡ˆè³‡æ–™å¤¾åˆå§‹åŒ–ç‚º Git repositoryï¼Œä¸¦æ¨é€åˆ°æ‚¨åœ¨ GitHub ä¸Šçš„æ–°å„²å­˜åº«ã€‚
2.  **é€£æ¥ Netlify:** ç™»å…¥ Netlifyï¼Œé¸æ“‡ "Add new site" -> "Import an existing project"ï¼Œç„¶å¾Œé€£æ¥åˆ°æ‚¨çš„ GitHub å„²å­˜åº«ã€‚
3.  **è¨­å®šå»ºç½®æŒ‡ä»¤:**
    *   **Build command:** `npm run build`
    *   **Publish directory:** `dist`
    *   **Functions directory:** `netlify/functions`
4.  **è¨­å®šç’°å¢ƒè®Šæ•¸:** åƒè€ƒä¸‹ä¸€ç¯€ï¼Œåœ¨ Netlify çš„ `Site settings` > `Build & deploy` > `Environment` ä¸­è¨­å®šå¿…è¦çš„ç’°å¢ƒè®Šæ•¸ã€‚
5.  **éƒ¨ç½²:** é»æ“Š "Deploy site"ã€‚

### å¾Œç«¯è³‡æ–™æ›´æ–° (æœ¬åœ° Python è…³æœ¬)

æœ¬æ‡‰ç”¨çš„æ ¸å¿ƒå¸‚å ´æ•¸æ“šä¾è³´æ–¼ä¸€å€‹ Python è…³æœ¬åœ¨æ‚¨çš„æœ¬æ©Ÿé›»è…¦ä¸ŠåŸ·è¡Œï¼Œä¸¦å°‡æ•¸æ“šä¸Šå‚³è‡³ Supabaseã€‚

**1. ç’°å¢ƒè¨­å®š**

è«‹ç¢ºä¿æ‚¨å·²å®‰è£ Python 3.8+ åŠä»¥ä¸‹å¥—ä»¶ï¼š
```bash
pip install yfinance pandas supabase tqdm twstock python-dotenv certifi numpy
```

**2. è¨­å®š API é‡‘é‘°**

åœ¨æ‚¨æ‰“ç®—å­˜æ”¾è…³æœ¬çš„ç›®éŒ„ä¸‹ï¼Œå»ºç«‹ä¸€å€‹åç‚º `.env` çš„æª”æ¡ˆï¼Œä¸¦å¡«å…¥æ‚¨çš„é‡‘é‘°ï¼š
```.env
SUPABASE_URL="https://...supabase.co"
SUPABASE_KEY="YOUR_SUPABASE_SERVICE_ROLE_KEY"
```
*   **SUPABASE_URL:** å¾æ‚¨çš„ Supabase å°ˆæ¡ˆè¨­å®š -> API -> Project URL å–å¾—ã€‚
*   **SUPABASE_KEY:** **è«‹å‹™å¿…ä½¿ç”¨ `service_role` é‡‘é‘°**ï¼Œå› ç‚ºè…³æœ¬éœ€è¦å¯«å…¥æ¬Šé™ã€‚æ­¤é‡‘é‘°ä½æ–¼ Project API Keys ä¸‹æ–¹ã€‚

**3. åŸ·è¡Œè…³æœ¬**

å°‡ä»¥ä¸‹ç¨‹å¼ç¢¼å„²å­˜ç‚º `update_stock_database.py`ï¼Œä¸¦èˆ‡ `.env` æª”æ¡ˆæ”¾åœ¨åŒä¸€ç›®éŒ„ä¸‹ã€‚

```python
import yfinance as yf
import pandas as pd
import numpy as np
import datetime
from supabase import create_client, Client
import logging
import time
from tqdm import tqdm
import twstock
import os
import certifi
import traceback
from dotenv import load_dotenv

# è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šè­‰æ›¸è·¯å¾‘ï¼Œä»¥è§£æ±º SSL éŒ¯èª¤
os.environ["REQUESTS_CA_BUNDLE"] = certifi.where()
os.environ["SSL_CERT_FILE"] = certifi.where()

# è¨­å®šæ—¥èªŒè¨˜éŒ„åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
# å»ºè­°: å°‡æ—¥èªŒæª”åæ”¹ç‚ºç›¸å°è·¯å¾‘ï¼Œä½¿å…¶èˆ‡è…³æœ¬æ”¾åœ¨åŒä¸€ç›®éŒ„ä¸‹
log_file_path = 'update_stock_database.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file_path, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š SUPABASE_URL å’Œ SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- è‚¡ç¥¨æ¸…å–®èˆ‡åŸºæœ¬è³‡æ–™è™•ç† ---
def get_tw_listed_stocks():
    """
    å¾ twstock åº«æŠ“å–æ‰€æœ‰å°ç£ä¸Šå¸‚è‚¡ç¥¨çš„ä»£ç¢¼å’Œåç¨±ã€‚

    Returns:
        list: åŒ…å«è‚¡ç¥¨ä»£ç¢¼å’Œåç¨±å­—å…¸çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ [{'code': '2330.TW', 'name': 'å°ç©é›»'}]ã€‚
    """
    logging.info("é–‹å§‹æŠ“å–TWSEä¸Šå¸‚è‚¡ç¥¨æ¸…å–®")
    stock_list = []
    codes = twstock.codes
    for code, info in codes.items():
        if info.type == 'è‚¡ç¥¨' and info.market == 'ä¸Šå¸‚':
            stock_list.append({'code': f"{code}.TW", 'name': info.name})
    logging.info(f"æŠ“å–åˆ° {len(stock_list)} æ”¯ä¸Šå¸‚è‚¡ç¥¨")
    return stock_list

def safe_get(d, key, default=None):
    """
    å®‰å…¨åœ°å¾å­—å…¸æˆ– pandas Series ä¸­ç²å–å€¼ï¼Œè™•ç†å¤šç¨®è³‡æ–™é¡å‹ã€‚
    """
    try:
        if isinstance(d, dict):
            val = d.get(key, default)
        elif isinstance(d, pd.Series):
            val = d.get(key, default) if key in d.index else default
        else:
            return default
        if isinstance(val, (pd.Series, np.ndarray, list)):
            if len(val) > 0:
                val = val[0]
            else:
                return default
        if isinstance(val, (int, float, np.number)):
            return float(val)
        return val
    except Exception:
        return default

def fmt_percent(val, default="N/A"):
    """
    å°‡æ•¸å€¼æ ¼å¼åŒ–ç‚ºç™¾åˆ†æ¯”å­—ç¬¦ä¸²ã€‚
    """
    try:
        if val is None or (isinstance(val, str) and val == "N/A"):
            return default
        if float(val) > 1:
            return f"{float(val):.2f}%"
        return f"{float(val) * 100:.2f}%"
    except Exception:
        return default

def clean_data_for_json(data_dict):
    """
    å°‡å­—å…¸ä¸­çš„ NaNã€None å’Œç„¡é™å¤§å€¼è½‰æ›ç‚º Noneï¼Œä»¥ç¬¦åˆ JSON è¦ç¯„ã€‚
    """
    cleaned_data = {}
    for key, value in data_dict.items():
        if isinstance(value, float):
            if np.isnan(value) or np.isinf(value):
                cleaned_data[key] = None
            else:
                cleaned_data[key] = value
        elif isinstance(value, list) and value and isinstance(value[0], (float, np.number)):
            cleaned_list = []
            for item in value:
                if np.isnan(item) or np.isinf(item):
                    cleaned_list.append(None)
                else:
                    cleaned_list.append(item)
            cleaned_data[key] = cleaned_list
        else:
            cleaned_data[key] = value
    return cleaned_data

# --- æŠ€è¡“æŒ‡æ¨™è¨ˆç®— ---
def calculate_rsi(data, periods=14):
    delta = data.diff()
    gain = delta.where(delta > 0, 0).rolling(window=periods).mean()
    loss = -delta.where(delta < 0, 0).rolling(window=periods).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_macd(data, fast=12, slow=26, signal=9):
    ema_fast = data.ewm(span=fast, adjust=False).mean()
    ema_slow = data.ewm(span=slow, adjust=False).mean()
    macd = ema_fast - ema_slow
    macd_signal = macd.ewm(span=signal, adjust=False).mean()
    return macd, macd_signal

def calculate_bollinger_bands(data, window=20, std=2):
    sma = data.rolling(window=window).mean()
    std_dev = data.rolling(window=window).std()
    bb_high = sma + std_dev * std
    bb_low = sma - std_dev * std
    return bb_high, bb_low

# --- è³‡æ–™åº«æ“ä½œèˆ‡è³‡æ–™è™•ç† ---
def get_stock_info(ticker_obj):
    info_dict = {}
    required_keys = ['longName', 'sector', 'marketCap', 'trailingPE', 'priceToBook', 'dividendYield', 'returnOnEquity', 'revenueGrowth']
    try:
        if hasattr(ticker_obj, 'fast_info'):
            fi = ticker_obj.fast_info
            info_dict = {k: getattr(fi, k, None) for k in required_keys}
        for k in required_keys:
            if k not in info_dict or info_dict[k] is None:
                info_dict[k] = ticker_obj.info.get(k) if hasattr(ticker_obj, 'info') and ticker_obj.info else None
    except Exception as e:
        logging.warning(f"{ticker_obj.ticker} è®€å– info/fast_info å¤±æ•—: {e}")
        info_dict = {k: None for k in required_keys}
    return info_dict

def get_stock_fundamentals(ticker_obj):
    info, gross_margin = {}, None
    try:
        info = get_stock_info(ticker_obj)
        try:
            financials = ticker_obj.financials
            if not financials.empty:
                latest_fin = financials.iloc[:, 0]
                gross_profit = latest_fin.get('Gross Profit')
                total_revenue = latest_fin.get('Total Revenue')
                if pd.notna(gross_profit) and pd.notna(total_revenue) and total_revenue != 0:
                    gross_margin = (gross_profit / total_revenue) * 100
        except Exception as e:
            logging.warning(f"{ticker_obj.ticker} æ¯›åˆ©ç‡è¨ˆç®—å¤±æ•—: {e}")
        return info, gross_margin
    except Exception as e:
        logging.error(f"{ticker_obj.ticker} è³‡æ–™è™•ç†å¤±æ•—: {e}")
        return {}, None

def fetch_stock_data(ticker, start_date, end_date):
    try:
        data = yf.download(ticker, start=start_date, end=end_date, progress=False)
        if data.empty:
            logging.warning(f"å¾ Yahoo Finance ç²å– {ticker} è³‡æ–™å¤±æ•—æˆ–ç‚ºç©º")
            return None
        return data
    except Exception as e:
        logging.error(f"ä¸‹è¼‰ {ticker} æ­·å²è³‡æ–™å¤±æ•—: {e}")
        return None

def fetch_historical_data_from_supabase(ticker, start_date, end_date):
    try:
        response = supabase.table("stocks").select("date, close").eq("ticker", ticker).gte("date", start_date).lte("date", end_date).order("date").execute()
        data = response.data
        if data:
            df = pd.DataFrame(data).set_index(pd.to_datetime(pd.DataFrame(data)['date'])).drop('date', axis=1)
            return df[['close']].rename(columns={'close': 'Close'})
        return None
    except Exception as e:
        logging.error(f"å¾ Supabase ç²å– {ticker} æ­·å²è³‡æ–™å¤±æ•—: {e}")
        return None

def process_and_prepare_data(ticker, data, historical_data, info, ticker_obj):
    if data is None or data.empty: return [], None

    combined_data = pd.concat([historical_data, data]).sort_index() if historical_data is not None and not historical_data.empty else data
    combined_data = combined_data[~combined_data.index.duplicated(keep='last')]
    
    # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
    combined_data['RSI'] = calculate_rsi(combined_data['Close'])
    combined_data['MACD'], combined_data['MACD_Signal'] = calculate_macd(combined_data['Close'])

    stock_data_list = []
    for index, row in data.iterrows():
        row_with_indicators = combined_data.loc[index]
        item = {
            "ticker": ticker, "date": index.strftime('%Y-%m-%d'),
            "open": float(row['Open']), "close": float(row['Close']),
            "high": float(row['High']), "low": float(row['Low']),
            "volume": int(row['Volume']),
            "rsi": float(row_with_indicators['RSI']), "macd": float(row_with_indicators['MACD']),
        }
        stock_data_list.append(clean_data_for_json(item))
    
    _, gross_margin = get_stock_fundamentals(ticker_obj)
    latest_data = combined_data.iloc[-1]
    
    fundamental_item = {
        "ticker": ticker, "company_name": safe_get(info, 'longName', ticker),
        "sector": safe_get(info, 'sector'), "market_cap": safe_get(info, 'marketCap'),
        "pe_ratio": safe_get(info, 'trailingPE'), "pb_ratio": safe_get(info, 'priceToBook'),
        "dividend_yield": safe_get(info, 'dividendYield'), "roe": safe_get(info, 'returnOnEquity'),
        "revenue_growth": safe_get(info, 'revenueGrowth'), "gross_margin": gross_margin,
        "recent_close": safe_get(latest_data, 'Close'), "volume": safe_get(data.iloc[-1], 'Volume'),
        "rsi": safe_get(latest_data, 'RSI'), "macd": safe_get(latest_data, 'MACD'),
        "updated_at": datetime.datetime.now().isoformat(),
    }
    
    return stock_data_list, clean_data_for_json(fundamental_item)

# --- ä¸»ç¨‹å¼ ---
def main():
    stock_list = get_tw_listed_stocks()
    end_date = datetime.datetime.now()
    start_date = end_date - datetime.timedelta(days=5)
    historical_start_date = end_date - datetime.timedelta(days=365)
    
    logging.info(f"é–‹å§‹æ›´æ–°è³‡æ–™åº«ï¼Œæ—¥æœŸç¯„åœ: {start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}")
        
    all_stocks_data, all_fundamentals_data = [], []
    
    for stock in tqdm(stock_list, desc="è™•ç†è‚¡ç¥¨é€²åº¦"):
        ticker_code = stock['code'].replace('.TW', '')
        try:
            ticker_obj = yf.Ticker(stock['code'])

            info, _ = get_stock_fundamentals(ticker_obj)
            historical_data = fetch_historical_data_from_supabase(ticker_code, historical_start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))
            data = fetch_stock_data(stock['code'], start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))
            
            if data is not None:
                stock_data, fundamental_data = process_and_prepare_data(ticker_code, data, historical_data, info, ticker_obj)
                if stock_data: all_stocks_data.extend(stock_data)
                if fundamental_data: all_fundamentals_data.append(fundamental_data)
            
            if len(all_fundamentals_data) >= 50:
                supabase.table("stock_fundamentals").upsert(all_fundamentals_data).execute()
                logging.info(f"æˆåŠŸä¸Šå‚³ {len(all_fundamentals_data)} ç­† stock_fundamentals è³‡æ–™")
                all_fundamentals_data = []
            
            if len(all_stocks_data) >= 50:
                supabase.table("stocks").upsert(all_stocks_data).execute()
                logging.info(f"æˆåŠŸä¸Šå‚³ {len(all_stocks_data)} ç­† stocks è³‡æ–™")
                all_stocks_data = []
            
            time.sleep(1)
        except Exception as e:
            logging.error(f"è™•ç† {ticker_code} å¤±æ•—: {e}\n{traceback.format_exc()}")
            continue
    
    if all_fundamentals_data:
        supabase.table("stock_fundamentals").upsert(all_fundamentals_data).execute()
        logging.info(f"æˆåŠŸä¸Šå‚³å‰©é¤˜ {len(all_fundamentals_data)} ç­† stock_fundamentals è³‡æ–™")
    if all_stocks_data:
        supabase.table("stocks").upsert(all_stocks_data).execute()
        logging.info(f"æˆåŠŸä¸Šå‚³å‰©é¤˜ {len(all_stocks_data)} ç­† stocks è³‡æ–™")
    
    logging.info("è‚¡ç¥¨è³‡æ–™åº«æ›´æ–°å®Œæˆã€‚")

if __name__ == "__main__":
    main()
```

**4. è‡ªå‹•åŒ–æ’ç¨‹**

å»ºè­°ä½¿ç”¨æ‚¨ä½œæ¥­ç³»çµ±çš„æ’ç¨‹å·¥å…·æ¯æ—¥è‡ªå‹•åŸ·è¡Œæ­¤è…³æœ¬ï¼ˆä¾‹å¦‚è¨­å®šåœ¨å‡Œæ™¨3é»ï¼‰ï¼Œä»¥ç¢ºä¿æ•¸æ“šåº«ä¿æŒæœ€æ–°ç‹€æ…‹ã€‚
-   **Windows:** ä½¿ç”¨ã€Œå·¥ä½œæ’ç¨‹å™¨ã€ã€‚
-   **macOS/Linux:** ä½¿ç”¨ `cron`ã€‚

### ç’°å¢ƒè®Šæ•¸è¨­å®š (Netlify)

æ‚¨éœ€è¦åœ¨ Netlify ç¶²ç«™è¨­å®šä¸­åŠ å…¥ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼Œä»¥ç¢ºä¿æ‰€æœ‰åŠŸèƒ½æ­£å¸¸é‹ä½œï¼š

| è®Šæ•¸åç¨± (Key) | ç”¨é€” |
| :--- | :--- |
| `VITE_API_KEY` | **Google Gemini API é‡‘é‘°** (AI æ ¸å¿ƒåŠŸèƒ½) |
| `VITE_GROQ_API_KEY` | **Groq API é‡‘é‘°** (AI å°ˆå®¶å°çµ„-åæ–¹æ„è¦‹) |
| `VITE_GITHUB_API_KEY`| **GitHub API é‡‘é‘°** (AI å°ˆå®¶å°çµ„-ç¬¬ä¸‰æ–¹æ¨¡å‹) |
| `VITE_NEWS2_API_KEY` | **ä¸»è¦æ–°èä¾†æº API é‡‘é‘° (Webz.io)** (æ–°èè¼¿æƒ…åˆ†æ) |
| `VITE_NEWS_API_KEY` | **å‚™ç”¨æ–°èä¾†æº API é‡‘é‘° (NewsAPI)** (æ–°èè¼¿æƒ…åˆ†æ) |
| `VITE_SUPABASE_URL` | **Supabase å°ˆæ¡ˆ URL** (æ ¸å¿ƒå¸‚å ´æ•¸æ“šåº«) |
| `VITE_SUPABASE_KEY` | **Supabase anon public é‡‘é‘°** (æ ¸å¿ƒå¸‚å ´æ•¸æ“šåº«) |
| `VITE_FIREBASE_API_KEY` | Firebase API é‡‘é‘° |
| `VITE_FIREBASE_AUTH_DOMAIN` | Firebase èªè­‰ç¶²åŸŸ |
| `VITE_FIREBASE_PROJECT_ID`| Firebase å°ˆæ¡ˆ ID |
| `VITE_FIREBASE_STORAGE_BUCKET`| Firebase å„²å­˜æ¡¶ |
| `VITE_FIREBASE_MESSAGING_SENDER_ID`| Firebase è¨Šæ¯ç™¼é€è€… ID |
| `VITE_FIREBASE_APP_ID` | Firebase æ‡‰ç”¨ ID |
| `VITE_FIREBASE_FUNCTIONS_URL` | Firebase Function è§¸ç™¼ URL (ç”¨æ–¼æ‰‹å‹•è§¸ç™¼å¾Œç«¯æ—¥èªŒæ¸…ç†) |

### âš ï¸ é‡è¦æé†’

*   **Firebase Functions**: `functions` è³‡æ–™å¤¾å…§çš„ Firebase Functions **éœ€è¦å¦å¤–ç¨ç«‹éƒ¨ç½²**ã€‚å®ƒè² è²¬å¾Œç«¯æ—¥èªŒçš„å®šæœŸæ¸…ç†ã€‚
*   **æœ¬åœ° Python è…³æœ¬**: è² è²¬æ›´æ–°å¸‚å ´æ•¸æ“šçš„ Python è…³æœ¬ (`update_stock_database.py`) **éœ€è¦åœ¨æ‚¨çš„æœ¬æ©Ÿé›»è…¦ä¸Šè¨­å®šä¸¦æ’ç¨‹åŸ·è¡Œ**ã€‚
*   **`.gitignore`**: è«‹ç¢ºä¿æ‚¨çš„ `.gitignore` æª”æ¡ˆåŒ…å« `.env`ï¼Œä»¥é¿å…å°‡æ‚¨çš„ API é‡‘é‘°ä¸Šå‚³åˆ°å…¬é–‹çš„ GitHub å„²å­˜åº«ã€‚


## âš ï¸ å…è²¬è²æ˜

æœ¬æ‡‰ç”¨ç¨‹å¼ç‚ºåŠŸèƒ½å±•ç¤ºå°ˆæ¡ˆï¼Œæ‰€æœ‰è³‡è¨Šèˆ‡ AI åˆ†æçµæœåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚è«‹åœ¨åšå‡ºä»»ä½•æŠ•è³‡æ±ºç­–å‰ï¼Œé€²è¡Œè‡ªå·±çš„ç ”ç©¶ä¸¦è«®è©¢å°ˆæ¥­äººå£«ã€‚